{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starbucks Rewards: Predicting Consumer Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is an experiment that determines how do we take this experimental data and discover what are the offers that excite people? So, the Capstone Project is about discovering what is the most valuable offer there is, not just for the customers as a whole but at an individual personal level.\n",
    "\n",
    "Link to an academic paper where machine learning was applied to this type of problem: http://ceur-ws.org/Vol-3026/paper18.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict if someone will reply to an offer, transaction data and demographic information must be combined. GitHub\n",
    "customers will also have access to the data and in the Data Sets section of the proposal, it is clearly stated that the repository and data sets are available.\n",
    "\n",
    "Using Gradient Boosting, a supervised learning method, we will analyze the attributes of customers to create customer classifications.\n",
    "\n",
    "This is a multi-class classification problem so the key metric we will use is f1-score. The simulating dataset only has one product, while Starbucks offers dozens of products. Therefore, this data set is a simplified version of the real Starbucks app.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset details\n",
    "\n",
    "portfolio.json\n",
    "* id (string) - offer id\n",
    "* offer_type (string) - a type of offer ie BOGO, discount, informational\n",
    "* difficulty (int) - the minimum required to spend to complete an offer\n",
    "* reward (int) - the reward is given for completing an offer\n",
    "* duration (int) - time for the offer to be open, in days\n",
    "* channels (list of strings)\n",
    "\n",
    "profile.json\n",
    "* age (int) - age of the customer \n",
    "* became_member_on (int) - date when customer created an app account\n",
    "* gender (str) - gender of the customer (note some entries contain 'O' for other rather than M or F)\n",
    "* id (str) - customer id\n",
    "* income (float) - customer's income\n",
    "\n",
    "transcript.json\n",
    "* event (str) - record description (ie transaction, offer received, offer viewed, etc.)\n",
    "* person (str) - customer id\n",
    "* time (int) - time in hours since the start of the test. The data begins at time t=0\n",
    "* value - (dict of strings) - either an offer id or transaction amount depending on the record\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = pd.read_json('data/portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('data/profile.json', orient='records', lines=True)\n",
    "transcript = pd.read_json('data/transcript.json', orient='records', lines=True)\n",
    "\n",
    "profile.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will handle missing values in the <strong>genders</strong> column in the `profile.json` data set by deleting rows\n",
    "\n",
    "Pros:\n",
    "Complete removal of data with missing values results in robust and highly accurate model\n",
    "Deleting a particular row or a column with no specific information is better, since it does not have a high weightage\n",
    "\n",
    "Cons:\n",
    "Loss of information and data\n",
    "Works poorly if the percentage of missing values is high (say 30%), compared to the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.dropna(inplace=True)\n",
    "profile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: We only consider customers who received offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transcript = transcript[transcript['event'].str.startswith('o')]\n",
    "new_transcript.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split / Explode a column of dictionaries into separate columns \n",
    "new_transcript = pd.concat([new_transcript.drop(['value'], axis=1), new_transcript['value'].apply(pd.Series)], axis=1)\n",
    "new_transcript.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transcript = new_transcript.dropna(subset = [\"offer_id\"])\n",
    "\n",
    "temp1 = portfolio.rename(columns={\"id\": \"offer_id\"})\n",
    "temp2 = profile.rename(columns={\"person\": \"id\"})\n",
    "\n",
    "data = pd.merge(new_transcript, temp1, on=\"offer_id\").rename(columns={\"person\": \"id\"})\n",
    "data = pd.merge(data, temp2, on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating additional features\n",
    "data['became_member_on'] = pd.to_datetime(data['became_member_on'],format='%Y%m%d')\n",
    "\n",
    "data[\"year\"] = data.became_member_on.dt.year\n",
    "data[\"month\"] = data.became_member_on.dt.month\n",
    "data[\"day\"] = data.became_member_on.dt.day\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['offer id',\n",
    "           'event',\n",
    "           'id',\n",
    "           'became_member_on',\n",
    "           'reward_y',\n",
    "           'reward_x',\n",
    "           'time',\n",
    "           'offer_type']\n",
    "           \n",
    "data.drop(to_drop, inplace=True, axis=1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will handle missing values in the <strong>income</strong> column in `data` by deleting rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice we only have 8 offers from previous 10 in the `portfolio.json` file. This is because two are merely informational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vals = {offer_id for offer_id in data['offer_id']}\n",
    "print(target_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set target to be offer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = data['offer_id']\n",
    "data.drop('offer_id', inplace=True, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object type to avoid error\n",
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "data['gender'] = lbl.fit_transform(data['gender'].astype(str))\n",
    "data['target'] = lbl.fit_transform(data['target'].astype(str))\n",
    "data['channels'] = lbl.fit_transform(data['gender'].astype(str))\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class distributions of offers completed (Exploratory Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_count = defaultdict(int)\n",
    "for offer in data['target']:\n",
    "    if offer in offer_count:\n",
    "        offer_count[offer]+=1\n",
    "    else:\n",
    "        offer_count[offer] = 1\n",
    "\n",
    "class_count = pd.DataFrame.from_dict(offer_count, orient='index')\n",
    "bar_plot = class_count.plot.bar(title=\"Number of occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data/train/train.csv', index = False)\n",
    "test.to_csv('data/test/test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = \"my-project-bucket-123\"\n",
    "region =\"us-east-1\" \n",
    "role = \"arn:aws:iam::657240468511:role/service-role/AmazonSageMaker-ExecutionRole-20211225T133929\"\n",
    "\n",
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "print(\"RoleArn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path_to_data = sagemaker.Session().upload_data(bucket=bucket, \n",
    "                                                  path='data/train', \n",
    "                                                  key_prefix='train')\n",
    "\n",
    "s3_path_to_data = sagemaker.Session().upload_data(bucket=bucket, \n",
    "                                                  path='data/test', \n",
    "                                                  key_prefix='test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using multiclass logistic regression against which we can benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_data = pd.read_csv ('data.csv')\n",
    "benchmark_train, benchmark_test = train_test_split(data, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(multi_class='multinomial', solver='saga', max_iter=10000 )\n",
    "X = benchmark_train.iloc[:, :-1]\n",
    "y = benchmark_train.iloc[:, -1:]\n",
    "model.fit(X, y.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "preds = model.predict(benchmark_test.iloc[:,:-1])\n",
    "score=f1_score(benchmark_test[\"target\"], preds, average='weighted')\n",
    "print(f\"f1-score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "**Note:** You will need to use the `train.py` script to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 's3://{}/output'.format(bucket)\n",
    "input_data = 's3://{}/'.format(bucket)\n",
    "\n",
    "metric_definitions = [{'Name': 'validation:f1', 'Regex': '.*\\[[0-9]+\\].*#011validation-f1:([-+]?[0-9]*\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*'}]\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point=\"train.py\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    framework_version=\"1.3-1\",\n",
    "    output_path=output_path,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = input_data + \"train\"\n",
    "test_input = input_data + \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_estimator.fit({'train': train_input, 'validation': test_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standout suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"max_depth\": IntegerParameter(2, 8),\n",
    "    \"eta\": ContinuousParameter(0.1, 0.5),\n",
    "    \"num_round\" : CategoricalParameter([10, 50, 100]),\n",
    "}\n",
    "\n",
    "objective_metric_name = \"validation:f1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_estimator = XGBoost(\n",
    "    entry_point=\"train.py\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    framework_version=\"1.3-1\",\n",
    "    output_path=output_path,\n",
    "\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    xgb_estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges, \n",
    "    max_jobs=2, \n",
    "    max_parallel_jobs=4 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit({'train': train_input, \"validation\": test_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final results compared to the benchmark result is higher by a large margin. \n",
    "Therefore the final model and solution is significant enough to have adequately solved the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.describe()['BestTrainingJob']['FinalHyperParameterTuningJobObjectiveMetric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = tuner.describe()['BestTrainingJob']['TunedHyperParameters']\n",
    "print(best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = int(best_estimator[\"max_depth\"])\n",
    "eta = float(best_estimator['eta'])\n",
    "num_round = int(best_estimator['num_round'][1:-1])\n",
    "\n",
    "print(\"max_depth: {}\".format(max_depth))\n",
    "print(\"eta: {}\".format(eta))\n",
    "print(\"num_round: {}\".format(num_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\": max_depth,\n",
    "    \"eta\": eta,\n",
    "    \"num_round\": num_round\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 's3://{}/output'.format(bucket)\n",
    "input_data = 's3://{}/'.format(bucket)\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point=\"train.py\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    framework_version=\"1.3-1\",\n",
    "    output_path=output_path,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_estimator.fit({'train': train_input, \"validation\": test_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model_data = xgb_estimator.model_data\n",
    "print(\"Model artifact saved at:\\n\", pt_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deploying and Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "endpoint_name = \"inference-pipeline-ep-\" + timestamp_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor=xgb_estimator.deploy(instance_type=\"ml.m5.large\", initial_instance_count=1, endpoint_name=endpoint_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "payload = '0,10,7,0,69,70000.0,2018,5,14'\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    content_type=\"text/csv\",\n",
    "    accept=\"application/json\")\n",
    "\n",
    "print(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
